---
title: "Feasts & fables: modern tools for time series analysis"
author: "Rob J Hyndman"
date: "FRB 28 Sep 2021"
toc: true
classoption: aspectratio=169
output:
  binb::monash:
    colortheme: monashwhite
    fig_width: 8
    fig_height: 3.3
    keep_tex: no
    includes:
      in_header: cornishheader.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, message = TRUE, warning = FALSE, cache = TRUE,
  dev.args = list(pointsize = 9)
)
```

```{r packages, echo=FALSE, include=FALSE}
# Load packages
library(fpp3)
library(patchwork)
library(glue)
library(stringr)
library(broom)

# Colors to be viridis for continuous scales and Okabe for discrete scales
options(
  digits = 3,
  width = 90,
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis",
  ggplot2.discrete.color = c("#D55E00", "#0072B2", "#009E73", "#CC79A7", "#E69F00", "#56B4E9", "#F0E442"),
  ggplot2.discrete.fill = c("#D55E00", "#0072B2", "#009E73", "#CC79A7", "#E69F00", "#56B4E9", "#F0E442")
)

# Neater data sets
global_economy <- global_economy %>%
  select(Year, Country, GDP, Imports, Exports, Population)
tourism <- tsibble::tourism %>%
  mutate(
    State = recode(State,
      "Australian Capital Territory" = "ACT",
      "New South Wales" = "NSW",
      "Northern Territory" = "NT",
      "Queensland" = "QLD",
      "South Australia" = "SA",
      "Tasmania" = "TAS",
      "Victoria" = "VIC",
      "Western Australia" = "WA"
    ),
    Region = stringr::str_remove(Region, "Australia's ")
  )
```

## E A Cornish (1909--1973)

\placefig{0}{1.37}{width=6.5cm, height=20cm}{cornish}
\begin{textblock}{8}(7,2)
\begin{itemize}
\item Foundation Fellow of the Australian Academy of Science (1954)
\item Chief of the CSIRO Mathematical Statistics Division (1954--1973)
\item Helped establish CSIRO Division of Computing Research (1963)
\end{itemize}
\end{textblock}

## E A Cornish (1909--1973)

\begin{block}{Rainfall papers}\fontsize{12}{13}\sf
\begin{enumerate}\tightlist
\item Cornish, EA \& Coote, GG (1958) \emph{The correlation of monthly rainfall with position and altitude of observing stations in South Australia.} CSIRO Div Math Stats Tech Paper 4.
\item Cornish, EA and Stenhouse, NS (1958) \emph{Inter-station correlations of monthly rainfall in South Australia.} CSIRO Div Math Stats Tech Paper 5.
\item Cornish, EA, Hill, GW, \& Evans, MJ (1961) \emph{Inter-station correlations of rainfall in southern Australia.} CSIRO Div Math Stats Tech Paper 10.
\end{enumerate}
\end{block}\fontsize{14}{15}\sf

  * Modelled monthly rainfall at 97 South Australian weather stations based on altitude, longitude and latitude.
  * Pairwise correlations of 6-day rainfall totals between weather stations: 90,585 correlation coefficients.

## Tidyverts packages

\begin{textblock}{3.8}(11,0)\begin{alertblock}{}\Large\textbf{tidyverts.org}\end{alertblock}\end{textblock}

\placefig{3}{1.6}{width=3.5cm}{tsibble.png}
\placefig{6.5}{1.6}{width=3.5cm}{tsibbledata.png}
\placefig{4.75}{4.6}{width=3.5cm}{feasts.png}
\placefig{8.25}{4.6}{width=3.5cm}{fable.png}

# What does modern time series data look like?

## Annual economic data

\fontsize{10}{11.2}\sf

```{r, echo = FALSE}
global_economy
```

\only<2->{\begin{textblock}{.75}(2.15,2.85)
\begin{alertblock}{}\fontsize{9}{9}\sf Index\phantom{dg}\end{alertblock}
\end{textblock}}
\only<3->{\begin{textblock}{1.7}(3.28,2.85)
\begin{alertblock}{}\fontsize{9}{9}\sf Key\phantom{dg}\end{alertblock}
\end{textblock}}
\only<4>{\begin{textblock}{6.7}(5.5,2.85)
\begin{alertblock}{}\fontsize{9}{9}\sf Measured variables\phantom{dg}\end{alertblock}
\end{textblock}}

## Australian tourism regions

```{r ausmap, echo=FALSE, message=FALSE, width=20, height=18, out.height="90%"}
library(sf)
# Use Okabe-Ito color-blind friendly color palette
state_colors <- c(
  `New South Wales` = "#56b4e9",
  `Victoria` = "#0072b2",
  `Queensland` = "#009e73",
  `South Australia` = "#f0e442",
  `Northern Territory` = "#d55e00",
  `Western Australia` = "#e69f00",
  `Tasmania` = "#cc79a7",
  `Australian Capital Territory` = "#cccccc"
)
read_sf("tourism/Tourism_Regions_2020.shp") %>%
  rename(State = "STE_NAME16") %>%
  ggplot() +
  geom_sf(aes(fill = State), alpha = 0.8) +
  theme_void() +
  scale_fill_manual(values = state_colors)
```

\only<2>{\begin{textblock}{6.5}(9.1,1.4)
\begin{block}{}\fontsize{12}{12}\sf
  \begin{itemize}\itemsep=0cm\parskip=0cm
    \item Quarterly data on visitor nights: 1998 -- 2017
    \item From \textit{National Visitor Survey}, interviews of 120,000 Australians aged 15+.
    \item Geographical hierarchy split by
    \begin{itemize}
    \item 8 states and territories
    \item 76 regions
    \end{itemize}
    \item Purpose:
    \begin{itemize}
    \item Holidays
    \item Business
    \item Visiting friends \& relatives
    \item Other
    \end{itemize}
  \end{itemize}
\end{block}
\end{textblock}}

## Quarterly tourism data

\fontsize{10}{11.3}\sf

```{r, echo = FALSE}
tourism
```

\only<2->{\begin{textblock}{1.1}(2.1,2.85)
\begin{alertblock}{}\fontsize{10}{10}\sf Index\phantom{dg}\end{alertblock}
\end{textblock}}
\only<3->{\begin{textblock}{3.9}(3.65,2.85)
\begin{alertblock}{}\fontsize{10}{10}\sf Keys\phantom{dg}\end{alertblock}
\end{textblock}}
\only<4>{\begin{textblock}{1.5}(7.95,2.85)
\begin{alertblock}{}\fontsize{10}{10}\sf Measure\phantom{dg}\end{alertblock}
\end{textblock}}

\begin{textblock}{3}(9,5)
\begin{block}{}\fontsize{10}{10}\sf Domestic visitor nights in thousands by state/region and purpose.\phantom{dg}\end{block}
\end{textblock}

## Australian electricity demand

\fontsize{10}{11.2}\sf

```{r, echo=FALSE}
bind_rows(
    as_tibble(vic_elec) %>% mutate(State = "VIC"),
    as_tibble(vic_elec) %>% mutate(State = "NSW"),
    as_tibble(vic_elec) %>% mutate(State = "SA"),
    as_tibble(vic_elec) %>% mutate(State = "WA"),
    as_tibble(vic_elec) %>% mutate(State = "TAS"),
    as_tibble(vic_elec) %>% mutate(State = "NT"),
    as_tibble(vic_elec) %>% mutate(State = "ACT"),
    as_tibble(vic_elec) %>% mutate(State = "QLD")
  ) %>%
  mutate(State = factor(State, levels=c("VIC","NSW","SA","WA","TAS","NT","QLD","ACT"))) %>%
  as_tsibble(index=Time, key = State) %>%
  select(Time, State, Date, Holiday, Temperature, Demand)
```

\only<2->{\begin{textblock}{1.1}(2.1,2.85)
\begin{alertblock}{}\fontsize{10}{10}\sf Index\phantom{dg}\end{alertblock}
\end{textblock}}
\only<3->{\begin{textblock}{0.8}(5.65,2.85)
\begin{alertblock}{}\fontsize{10}{10}\sf Key\phantom{dg}\end{alertblock}
\end{textblock}}
\only<4>{\begin{textblock}{6.5}(6.85,2.85)
\begin{alertblock}{}\fontsize{10}{10}\sf Measures\phantom{dg}\end{alertblock}
\end{textblock}}

## Characteristics of modern time series

  * Often observed at sub-daily frequency over a long time.
  * Multiple keys which may be nested.
  * Multiple seasonal patterns.
  * Multiple measures for each combination of index and keys.
  
\pause\vspace*{0.3cm}

### `tsibble` objects
\fontsize{12}{13}\sf

  * A `tsibble` allows storage and manipulation of multiple time series in R.
  * It contains:

    + An index: time information about the observation
    + Key variable(s): optional unique identifiers for each series
    + Measured variable(s): numbers of interest and any other variable

# Feature-based time series analysis

## STL decomposition

```{r, echo=FALSE, fig.height=6, fig.width=11}
tourism %>%
  filter(Purpose == "Holiday", Region == "Snowy Mountains") %>%
  model(STL(Trips ~ trend(window = 13))) %>%
  components() %>%
  autoplot() +
  labs(title = "STL decomposition: Holidays in Snowy Mountains",
       y = "Overnight trips (thousands)")
```

## Strength of seasonality and trend

\begin{alertblock}{STL decomposition}
\centerline{$y_t = T_t+S_t+R_t$}
\end{alertblock}

### Seasonal strength
$$\max\left(0, 1-\frac{\text{Var}(R_t)}{\text{Var}(S_t+R_t)}\right)$$

### Trend strength
$$\max\left(0, 1-\frac{\text{Var}(R_t)}{\text{Var}(T_t+R_t)}\right)$$

## STL-based features
\fontsize{9}{9}\sf

```{r features}
tourism %>%
  features(Trips, feat_stl)
```

## STL-based features
\fontsize{9}{9}\sf

```{r features-plot, fig.height=4, fig.width=6, out.height="67%"}
tourism %>%
  features(Trips, feat_stl) %>%
  ggplot(aes(x = trend_strength, y = seasonal_strength_year, col = Purpose)) +
  geom_point() + facet_wrap(vars(State))
```

\only<2->{\begin{textblock}{5.3}(9.8,6.6)
\begin{alertblock}{}\fontsize{12}{12}\sf
\begin{itemize}\tightlist
\item Holidays more seasonal than other travel.
\item WA has strongest trends.
\end{itemize}
\end{alertblock}\end{textblock}}

## STL-based features

Find the most seasonal time series:

\fontsize{9}{9}\sf

```{r extreme, fig.height=2}
tourism %>%
  features(Trips, feat_stl) %>%
  filter(seasonal_strength_year == max(seasonal_strength_year)) %>%
  left_join(tourism, by = c("State", "Region", "Purpose")) %>%
  ggplot(aes(x = Quarter, y = Trips)) +
  geom_line() +
  facet_grid(vars(State, Region, Purpose))
```

## STL-based features

Find the most trended time series:

\fontsize{9}{9}\sf

```{r extreme3, fig.height=2}
tourism %>%
  features(Trips, feat_stl) %>%
  filter(trend_strength == max(trend_strength)) %>%
  left_join(tourism, by = c("State", "Region", "Purpose")) %>%
  ggplot(aes(x = Quarter, y = Trips)) +
  geom_line() +
  facet_grid(vars(State, Region, Purpose))
```

```{r pca, echo=FALSE}
# Save pdf figures
savepdf <- function(file, width = 16, height = 10) {
  fname <<- paste("figs/", file, ".pdf", sep = "")
  pdf(fname, width = width / 2.54, height = height / 2.54, pointsize = 10)
  par(mgp = c(2.2, 0.45, 0), tcl = -0.4, mar = c(3.3, 3.6, 1.1, 1.1))
}
endpdf <- function() {
  crop::dev.off.crop(fname)
}
# Compute features
tourism_features <- tourism %>%
  features(Trips, feature_set(pkgs = "feasts"))
# Compute PCs
pcs <- tourism_features %>%
  select(-State, -Region, -Purpose) %>%
  prcomp(scale = TRUE) %>%
  broom::augment(tourism_features)
# Save some PC plots
savepdf("pca1", 18, 10)
pcs %>% ggplot(aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point() +
  theme(aspect.ratio = 1)
endpdf()
savepdf("pca2", 18, 10)
pcs %>% ggplot(aes(x = .fittedPC1, y = .fittedPC2, col = State)) +
  geom_point() +
  theme(aspect.ratio = 1)
endpdf()
savepdf("pca3", 18, 10)
pcs %>% ggplot(aes(x = .fittedPC1, y = .fittedPC2, col = Purpose)) +
  geom_point() +
  theme(aspect.ratio = 1)
endpdf()
# Find outliers
outliers <- pcs %>%
  filter(.fittedPC1 > 12 | (.fittedPC1 > 10 & .fittedPC2 < 0))
savepdf("pca4", 18, 10)
pcs %>% ggplot(aes(x = .fittedPC1, y = .fittedPC2, col = Purpose)) +
  geom_point() +
  theme(aspect.ratio = 1) +
  geom_point(data = outliers, aes(x = .fittedPC1, y = .fittedPC2), col = "black", shape = 1, size = 3)
endpdf()
```

## Time series features
\fontsize{9}{9}\sf

```{r tourismfeatures, eval=FALSE}
tourism_features <- tourism %>%
  features(Trips, feature_set(pkgs = "feasts"))
```

\vspace*{-0.5cm}\fontsize{8}{8}\sf

```{r echo=FALSE}
tourism_features
```

\begin{textblock}{5}(9.6,1.5)
\begin{alertblock}{}\fontsize{10}{12}\sf
All features from the feasts package
\end{alertblock}
\end{textblock}

## Reduced feature space
\fontsize{9}{9}\sf

```{r pcatable}
pcs <- tourism_features %>%
  select(-State, -Region, -Purpose) %>%
  prcomp(scale = TRUE) %>%
  augment(tourism_features)
```

\vspace*{-0.5cm}\fontsize{8}{8}\sf

```{r echo=FALSE}
pcs
```

\begin{textblock}{5}(9.6,1.5)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

## Reduced feature space
\fontsize{9}{9}\sf

\begin{textblock}{3.3}(.4,3)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

```r
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2)) +
  geom_point() + theme(aspect.ratio=1)
```

\placefig{4}{2.6}{height=6.4cm, width=12cm}{pca1}
\vspace*{10cm}

## Reduced feature space
\fontsize{9}{9}\sf

\begin{textblock}{3.3}(.4,3)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

```r
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2, col=State)) +
  geom_point() + theme(aspect.ratio=1)
```

\placefig{4}{2.6}{height=6.4cm, width=12cm}{pca2}
\vspace*{10cm}

## Reduced feature space
\fontsize{9}{9}\sf

\begin{textblock}{3.3}(.4,3)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

```r
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2, col=Purpose)) +
  geom_point() + theme(aspect.ratio=1)
```

\placefig{4}{2.6}{height=6.4cm, width=12cm}{pca3}
\vspace*{10cm}

## Anomaly detection using time series features
\fontsize{9}{9}\sf

\begin{textblock}{3.3}(.4,3)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

```r
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2, col=Purpose)) +
  geom_point() + theme(aspect.ratio=1)
```

\placefig{4}{2.6}{height=6.4cm, width=12cm}{pca4}
\vspace*{10cm}

## Anomaly detection using time series features
\fontsize{8}{8}\sf

```{r outliers2, fig.height=6, fig.width=10, out.width="100%", dependson='pca', echo=FALSE}
out <- outliers %>%
  left_join(tourism, by = c("State", "Region", "Purpose")) %>%
  mutate(
    Series = glue("{State}", "{Region}", "{Purpose}", .sep = "\n\n"),
    Series = as.character(Series)
  ) %>%
  select(Quarter, Series, Trips, .fittedPC2)
ordering <- out %>% 
  select(Series,.fittedPC2) %>%
  arrange(desc(.fittedPC2)) %>% 
  select(Series) %>%
  distinct(Series) %>%
  pull(Series)
out %>%
  mutate(Series = factor(Series, levels=ordering)) %>%
  select(Series, Quarter, Trips) %>%
  ggplot(aes(x = Quarter, y = Trips)) + geom_line() +
  facet_grid(Series ~ ., scales = "free_y") +
  ggtitle("Outlying time series in PC space")
```

# Probabilistic forecasting for large time series

```{r austa, include=FALSE}
austa <- tourism %>% summarise(Trips = sum(Trips)/1e3)
# Fit ETS model
fit <- austa %>%
  model(ETS(Trips ~ trend("A")))
# Product forecasts
fc <- forecast(fit, h = 16)
# Simulate 100 future sample paths
set.seed(1967)
sim <- fit %>%
  generate(h = 16, times = 100) %>%
  mutate(
    replicate = factor(.rep, levels = 1:100, labels = paste("Future", 1:100)),
    .rep = as.numeric(.rep)
  ) %>%
  as_tibble()
# Nice colors
cols <- scale_color_manual(
  values = c("#D55E00", "#0072B2", "#009E73", "#CC79A7", "#E69F00", "#56B4E9", "#F0E442", sample(rainbow(93))),
  breaks = paste("Future", 1:100),
  name = " "
)
# Now build up some plots with alignment
p1 <- austa %>%
  bind_rows(new_data(austa, 16)) %>%
  as_tibble() %>%
  ggplot(aes(x = Quarter, y = Trips)) +
  geom_line() +
  labs(
    x = "Quarter",
    y = "Overnight trips (millions)",
    title = "Total Australian domestic overnight trips"
  ) +
  scale_x_yearquarter(
    breaks = yearquarter(seq(as.Date("2000-01-01"), by = "5 years", l = 5)),
    labels = paste(seq(2000, 2020, by = 5),"Q1"),
    minor_breaks = yearquarter(seq(as.Date("2000-01-01"), by = "1 year", l = 25)),
  ) +
  ylim(min(austa$Trips, sim$.sim, na.rm = TRUE), max(austa$Trips, sim$.sim, na.rm = TRUE))
p2 <- p1 + cols +
  geom_line(aes(y = .sim, group = replicate, color = replicate),
    data = sim %>% filter(.rep <= 1)
  )
p3 <- p1 + cols +
  geom_line(aes(y = .sim, group = replicate, color = replicate),
    data = sim %>% filter(.rep <= 2)
  )
p4 <- p1 + cols +
  geom_line(aes(y = .sim, group = replicate, color = replicate),
    data = sim %>% filter(.rep <= 3)
  )
p5 <- p1 + cols +
  geom_line(aes(y = .sim, group = replicate, color = replicate),
    data = sim %>% filter(.rep <= 10)
  )
p6 <- p1 + cols +
  geom_line(aes(y = .sim, group = replicate, color = replicate), alpha = 0.5, data = sim) +
  guides(color = "none")
p7 <- p1 +
  geom_line(aes(y = .sim, group = replicate, color = replicate), alpha = 0.5, col = "gray", data = sim) +
  guides(color = "none")
p8 <- p7 + autolayer(fc, level = c(50, 90))
p9 <- p8 + coord_cartesian(xlim = as.Date(c("2013-01-01", "2021-08-01"))) +
  scale_x_yearquarter(
    breaks = yearquarter(seq(as.Date("2000-01-01"), by = "2 years", l = 11)),
    labels = paste(seq(2000, 2020, by = 2),"Q1"),
    minor_breaks = yearquarter(seq(as.Date("2000-01-01"), by = "1 year", l = 25)),
  )
aligned_plots <- align_patches(p1, p2, p3, p4, p5, p6, p7, p8, p9)

for (i in seq(9)) {
  pdf(paste0("figs/austa", i, ".pdf"), height = 3.3, width = 8)
  print(aligned_plots[[i]])
  dev.off()
}
```

## Random futures

\forecast\pause
\includegraphics[height=8cm]{austa1}

## Random futures

\forecast
\includegraphics[height=8cm]{austa2}
\simfutures

## Random futures

\forecast
\includegraphics[height=8cm]{austa3}
\simfutures

## Random futures

\forecast
\includegraphics[height=8cm]{austa4}
\simfutures

## Random futures

\forecast
\includegraphics[height=8cm]{austa5}
\simfutures

## Random futures

\forecast
\includegraphics[height=8cm]{austa6}
\simfutures

## Random futures

\forecast
\includegraphics[height=8cm]{austa7}
\simfutures

## Random futures

\forecast
\includegraphics[height=8cm]{austa8}
\simfutures

## Random futures

\forecast
\includegraphics[height=8cm]{austa9}
\simfutures

## Model fitting
\fontsize{9}{9}\sf

```{r holiday-model}
tourism_fit <- tourism %>%
  filter(year(Quarter) < 2015) %>%
  model(
    ets = ETS(Trips),
    arima = ARIMA(Trips)
  ) %>%
  mutate(ensemble = (ets + arima)/2)
```

```{r holiday-model2, echo=FALSE, dependson='holiday-model'}
tourism_fit
```

## Producing forecasts

\fontsize{9}{9}\sf

```{r holiday-fc, echo = TRUE, dependson='holiday-model'}
tourism_fc <- tourism_fit %>%
  forecast(h = "3 years")
```

```{r holiday-fbl, echo = FALSE, dependson='holiday-fc'}
print(tourism_fc, n = 10)
```

## Visualising forecasts
\fontsize{9}{9}\sf

```{r fcviz, include=FALSE, dependson='holiday-fc'}
p1 <- tourism_fc %>%
  filter(Region == "Adelaide", Purpose=="Business") %>%
  autoplot(tourism %>% filter(year(Quarter) < 2015), level = NULL) +
  labs(title = "Adelaide Business Trips", y = "Thousands of visitors") +
  guides(color = guide_legend(title = "Forecast"))
p2 <- tourism_fc %>%
  filter(Region == "Adelaide", Purpose=="Business", .model == "arima") %>%
  autoplot(tourism %>% filter(year(Quarter) < 2015)) +
  labs(title = "Adelaide Business Trips", y = "Thousands of visitors") +
  guides(color = guide_legend(title = "Forecast"))
aligned_plots <- align_patches(p1,p2)
for (i in seq(2)) {
  pdf(paste0("figs/austafc", i, ".pdf"), height = 2.9, width = 8)
  print(aligned_plots[[i]])
  dev.off()
}
```

```r
tourism_fc %>%
  filter(Region == "Adelaide", Purpose=="Business") %>%
  autoplot(tourism, level = NULL) +
  labs(title = "Adelaide Business Trips", y = "Thousands of visitors") +
  guides(color = guide_legend(title = "Forecast"))
```

\includegraphics[height=8cm]{austafc1}

## Visualising forecasts
\fontsize{9}{9}\sf

```r
tourism_fc %>%
  filter(Region == "Adelaide", Purpose=="Business", .model == "arima") %>%
  autoplot(tourism) +
  labs(title = "Adelaide Business Trips", y = "Thousands of visitors") +
  guides(color = guide_legend(title = "Forecast"))
```

\includegraphics[height=8cm]{austafc2}

# Evaluating probabilistic forecasts

## Evaluating probabilistic forecasts

```{r traintest, fig.height=1, echo=FALSE, cache=TRUE}
train <- 1:18
test <- 19:24
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlim = c(0, 26), ylim = c(0, 2), xaxt = "n", yaxt = "n", bty = "n", xlab = "", ylab = "", type = "n")
arrows(0, 0.5, 25, 0.5, 0.05)
points(train, train * 0 + 0.5, pch = 19, col = "#0072B2")
points(test, test * 0 + 0.5, pch = 19, col = "#D55E00")
text(26, 0.5, "time")
text(10, 1, "Training data", col = "#0072B2")
text(21, 1, "Test data", col = "#D55E00")
```

```{r tscvplots, echo=FALSE}
tscv_plot <- function(.init, .step, h = 1) {
  expand.grid(
    time = seq(26),
    .id = seq(trunc(20 / .step))
  ) %>%
    group_by(.id) %>%
    mutate(
      observation = case_when(
        time <= ((.id - 1) * .step + .init) ~ "train",
        time %in% c((.id - 1) * .step + .init + h) ~ "test",
        TRUE ~ "unused"
      )
    ) %>%
    ungroup() %>%
    filter(.id <= 26 - .init) %>%
    ggplot(aes(x = time, y = .id)) +
    geom_segment(
      aes(x = 0, xend = 27, y = .id, yend = .id),
      arrow = arrow(length = unit(0.015, "npc")),
      col = "black", size = .25
    ) +
    geom_point(aes(col = observation), size = 2) +
    scale_y_reverse() +
    scale_color_manual(values = c(train = "#0072B2", test = "#D55E00", unused = "gray")) +
    # theme_void() +
    # geom_label(aes(x = 28.5, y = 1, label = "time")) +
    guides(col = FALSE) +
    labs(x = "time", y = "") +
    theme_void() +
    theme(axis.title = element_text())
}
```

```{r qs, include=FALSE}
# Run to generate the graphs
qp <- function(p, y) {
  if (length(p) > 1 & length(y) > 1) {
    stop("Either p or y should be a scalar")
  }
  fp <- qgamma(p, 2)
  2 * (1 - p) * abs(y - fp) * (y < fp) + 2 * p * abs(y - fp) * (y >= fp)
}
gamma <- tibble(
  y = seq(0, 10, l = 101),
  f = dgamma(y, 2)
)
actual <- 3
```

\vspace*{1cm}

```{r pdf1, dependson='qs', echo=FALSE}
# Single pdf graph for median
prob <- 0.5
qactual <- qgamma(prob, 2)
gamma %>%
  ggplot(aes(x = y, y = f)) +
  geom_line() +
  geom_point(aes(x = actual, y = y), data = tibble(actual = actual, y = 0), col="#D55E00") +
  geom_label(aes(x = actual, y = 0.02, label = "Actual"), col="#D55E00") +
  labs(y = "Forecast probability density", x = latex2exp::TeX("Quantile $q_{p}$")) +
  geom_line(aes(x = y, y = f),
    col = "blue", linetype = 2,
    data = tibble(y = rep(qactual, 2), f = c(dgamma(qactual, 2), 0))
  ) +
  geom_label(aes(x = qactual, y = 0.02, label = "Median"), col = "blue") +
  geom_label(aes(x = qactual, y = -0.01, label = "0.5 quantile"), col = "blue") +
  coord_cartesian(ylim = c(-0, 0.375), xlim = c(0, 10), expand = FALSE, clip = "off")
```

## Evaluating probabilistic forecasts

```{r ref.label="traintest", fig.height=1, echo=FALSE, cache=TRUE}
```

\vspace*{1cm}

```{r pdf2, dependson='qs', echo=FALSE}
# Single pdf graph for 0.8 quantile
prob <- 0.9
qactual <- qgamma(prob, 2)
gamma %>%
  ggplot(aes(x = y, y = f)) +
  geom_line() +
  geom_point(aes(x = actual, y = y), data = tibble(actual = actual, y = 0), col="#D55E00") +
  geom_label(aes(x = actual, y = 0.02, label = "Actual"), col="#D55E00") +
  labs(y = "Forecast probability density", x = latex2exp::TeX("Quantile $q_{p}$")) +
  geom_line(aes(x = y, y = f),
    col = "blue", linetype = 2,
    data = tibble(y = rep(qactual, 2), f = c(dgamma(qactual, 2), 0))
  ) +
  geom_label(aes(x = qactual, y = -0.01, label = paste(sprintf("%.2f", prob), "quantile")), col = "blue") +
  coord_cartesian(ylim = c(-0, 0.375), xlim = c(0, 10), expand = FALSE, clip = "off")
```

## Evaluating probabilistic forecasts

```{r pdfqs, dependson='qs', echo=FALSE}
# pdf plus quantile score graph for several quantiles
prob <- c(0.1, 0.3, 0.5, 0.7, 0.9)
qactual <- qgamma(prob, 2)
qpactual <- qp(prob, actual)
for (i in seq_along(prob)) {
  p1 <- gamma %>%
    ggplot(aes(x = y, y = f)) +
    geom_line() +
    geom_point(aes(x = actual, y = y), data = tibble(actual = actual, y = 0), col="#D55E00") +
    labs(y = "Forecast probability density", x = latex2exp::TeX("Quantile $q_{p}$")) +
    geom_line(aes(x = y, y = f),
      col = "blue", linetype = 2,
      data = tibble(y = rep(qactual[i], 2), f = c(dgamma(qactual[i], 2), 0))
    ) +
    geom_label(aes(x = actual, y = 0.03, label = "Actual"), col="#D55E00") +
    geom_label(aes(x = qactual[i], y = -0.02, label = paste(sprintf("%.2f", prob[i]), "quantile")), col = "blue") +
    coord_cartesian(ylim = c(-0, 0.375), xlim = c(0, 10), expand = FALSE, clip = "off")
  p2 <- tibble(
    y = seq(0, 10, l = 101),
    Q = qp(prob[i], y)
  ) %>%
    ggplot(aes(x = y, y = Q)) +
    geom_line() +
    labs(
      x = latex2exp::TeX("Quantile $q_{p}$"),
      y = latex2exp::TeX("Quantile score $S_{p}$")
    ) +
    geom_line(aes(x = y, y = Q),
      col = "red", linetype = 2,
      data = tibble(y = c(actual, actual), Q = c(14.5, qpactual[i]))
    ) +
    geom_line(aes(x = y, y = Q),
      col = "red", linetype = 2,
      data = tibble(y = c(actual, 0), Q = rep(qpactual[i], 2))
    ) +
    geom_line(aes(x = y, y = f),
      col = "blue", linetype = 2,
      data = tibble(y = rep(qactual[i], 2), f = c(0, 13.5))
    ) +
    coord_cartesian(ylim = c(0, 11.6), xlim = c(0, 10), expand = FALSE, clip = "off")
  pdf(paste0("figs/pdfqs", i, ".pdf"), width = 15 / 1.5, height = 8 / 1.5)
  print(p1 / p2)
  crop::dev.off.crop()
  if(i==5) {
    pdf(paste0("figs/pdfqs", i, "a.pdf"), width = 14.9 / 1.5, height = 4 / 1.5)
    print(p1)
    crop::dev.off.crop()
  }
}
```

\only<7>{\placefig{0.2}{1.4}{width=14.7cm,height=20cm}{pdfqs1}}
\only<6>{\placefig{0.2}{1.4}{width=14.7cm,height=20cm}{pdfqs2}}
\only<5>{\placefig{0.2}{1.4}{width=14.7cm,height=20cm}{pdfqs3}}
\only<4>{\placefig{0.2}{1.4}{width=14.7cm,height=20cm}{pdfqs4}}
\only<3>{\placefig{0.2}{1.4}{width=14.7cm,height=20cm}{pdfqs5}}
\only<1-2>{\placefig{0.4}{1.5}{width=14.4cm,height=20cm}{pdfqs5a}}

\only<2->{\begin{textblock}{5.8}(9.8,.4)\fontsize{11}{12}\sf
\begin{alertblock}{}\vspace*{-0.3cm}
\begin{align*}
q_{p} &= \text{quantile forecast with prob. $p$}\\
y &= \text{observation}
\end{align*}
\end{alertblock}\vspace*{-0.3cm}
\begin{alertblock}{Quantile score}\vspace*{-0.1cm}
$$
  S_p(y) = \begin{cases}
  2(1 - p) \big|y - q_{p}\big|, & \text{if $y < q_{p}$}\\
  2p \big|y - q_{p}\big|, & \text{if $y \ge q_{p}$} \end{cases}
$$
\end{alertblock}
\end{textblock}}


## Evaluating probabilistic forecasts

```{r pdfqs2, include=FALSE, dependson='qs'}
qs <- seq(0, 10, l = 200)
prob <- pgamma(qs, 2)
prob <- c(prob[prob <= 0.999], 0.9999)
for (i in seq_along(prob)) {
  qactual <- qgamma(prob[i], 2)
  qpactual <- qp(prob[i], actual)
  p1 <- gamma %>%
    ggplot(aes(x = y, y = f)) +
    geom_line() +
    geom_point(aes(x = actual, y = y), data = tibble(actual = actual, y = 0), col = "#D55E00") +
    geom_label(aes(x = actual, y = 0.02, label = "Actual"), col = "#D55E00") +
    labs(y = "Forecasting probability density", x = latex2exp::TeX("Quantile $q_{p}$")) +
    geom_line(aes(x = y, y = f),
      col = "blue", linetype = 2,
      data = tibble(y = rep(qactual, 2), f = c(dgamma(qactual, 2), -0.1))
    ) +
    coord_cartesian(ylim = c(-0, 0.375), xlim = c(0, 10), expand = FALSE, clip = "off")
  p2 <- tibble(
    y = seq(0, 10, l = 101),
    Q = qp(prob[i], y)
  ) %>%
    ggplot(aes(x = y, y = Q)) +
    geom_line() +
    labs(
      x = latex2exp::TeX("Quantile $q_{p}$"),
      y = latex2exp::TeX("Quantile score $S_{p}$")
    ) +
    geom_line(aes(x = y, y = Q),
      col = "red", linetype = 2,
      data = tibble(y = rep(actual, 2), Q = c(14.5, qpactual))
    ) +
    geom_line(aes(x = y, y = Q),
      col = "red", linetype = 2,
      data = tibble(y = c(actual, -1), Q = rep(qpactual, 2))
    ) +
    geom_line(aes(x = y, y = f),
      col = "blue", linetype = 2,
      data = tibble(y = rep(qactual, 2), f = c(0, 12))
    ) +
    geom_label(aes(x = qactual, y = 11.6, label = paste(sprintf("%.3f", prob[i]), "quantile")), col = "blue") +
    coord_cartesian(ylim = c(0, 11.6), xlim = c(0, 10), expand = FALSE, clip = "off")

  p3data <- tibble(
    p = prob,
    Q = qp(prob, actual)
  ) %>%
    filter(p <= prob[i])
  p3 <- p3data %>%
    ggplot(aes(x = p, y = Q)) +
    geom_line(col = "red") +
    geom_polygon(
      fill = "#ffbbbb",
      data = bind_rows(p3data, tibble(p = prob[i], Q = 0))
    ) +
    geom_line(data = tibble(p = c(prob[i], 1), Q = rep(qpactual, 2)), col = "red", linetype = 2) +
    # geom_point(data=tibble(p=prob[i],Q=qpactual), col='red') +
    labs(
      x = latex2exp::TeX("Probability p"),
      y = latex2exp::TeX("Quantile score $S_{p}$")
    ) +
    coord_cartesian(ylim = c(0, 11.6), xlim = c(0, 1), expand = FALSE, clip = "off")

  pdf(file = paste0("figs/qs", i, ".pdf"), width = 15 / 1.5, height = 8 / 1.5)
  print((plot_spacer() | p1) / (p3 | p2))
  crop::dev.off.crop()
}
```

\begin{textblock}{18}(0.3,1.4)
\animategraphics[width=14cm,height=20cm,keepaspectratio]{185}{figs/qs}{1}{185}
\end{textblock}

## Evaluating probabilistic forecasts

\begin{textblock}{18}(0.3,1.4)
\includegraphics[width=14cm,height=20cm,keepaspectratio]{figs/qs185}
\end{textblock}

\only<2>{\begin{textblock}{4}(2,7)\fontsize{11}{11}\sf
\textcolor{red}{Area = CRPS}
\end{textblock}}


## Evaluating probabilistic forecasts
\fontsize{10}{11}\sf

```{r fcaccuracy0, dependson='holiday-fc'}
tourism_fc %>%
  accuracy(tourism, measures = list(MSE=MSE, CRPS=CRPS))
```

\vspace*{10cm}


## Evaluating probabilistic forecasts
\fontsize{10}{11}\sf

```{r fcaccuracy1, dependson='holiday-fc'}
tourism_fc %>%
  accuracy(tourism, measures = list(MSE=MSE, CRPS=CRPS)) %>%
  group_by(.model) %>%
  summarise(MSE = mean(MSE), CRPS=mean(CRPS))
```

\vspace*{10cm}

# Forecast reconciliation

## Hierarchical time series
\fontsize{13}{14}\sf

A \alert{\textbf{hierarchical time series}} is a collection of several time series that are linked together in a hierarchical structure.

\begin{minipage}{9.6cm}
\begin{block}{}
\begin{tikzpicture}
\tikzstyle{every node}=[ellipse,draw,inner sep=0.2pt,fill=red!15]
\tikzstyle[level distance=.1cm]
\tikzstyle[sibling distance=7cm]
\tikzstyle{level 1}=[sibling distance=33mm,set style={{every node}+=[fill=blue!15]}]
\tikzstyle{level 2}=[sibling distance=10mm,font=\small,set style={{every node}+=[fill=yellow]}]
\node{Total}[edge from parent fork down]
 child {node {A}
   child {node {AA}}
   child {node {AB}}
   child {node {AC}}
 }
 child {node {B}
   child {node {BA}}
   child {node {BB}}
   child {node {BC}}
 }
 child {node {C}
   child {node {CA}}
   child {node {CB}}
   child {node {CC}}
 };
\end{tikzpicture}
\end{block}
\end{minipage}

\pause\alert{Examples}\vspace*{-0.2cm}

 * Tourism demand by states, zones, regions

## Grouped time series
\fontsize{13}{14}\sf

A \alert{\textbf{grouped time series}} is a collection of time series that can be grouped together in a number of non-hierarchical ways.

\begin{minipage}{9.2cm}
\begin{block}{}
\begin{tikzpicture}[level distance=1.5cm]
\tikzstyle{every node}=[ellipse,draw,inner sep=0.2pt,outer sep=0pt, fill=red!15]
\tikzstyle{level 1}=[sibling distance=23mm,set style={{every node}+=[fill=blue!15]},level distance=1cm]
\tikzstyle{level 2}=[sibling distance=10mm,font=\small,set style={{every node}+=[fill=yellow]}, level distance=0.9cm]
\node{Total}[edge from parent fork down]
 child {node {A}
   child {node {AX}}
   child {node {AY}}
 }
 child {node {B}
   child {node {BX}}
   child {node {BY}}
 };
\end{tikzpicture}\hspace*{1cm}
\begin{tikzpicture}[level distance=1.5cm]
\tikzstyle{every node}=[ellipse,draw,inner sep=0.2pt,outer sep=0pt, fill=red!15]
\tikzstyle{level 1}=[sibling distance=23mm,set style={{every node}+=[fill=blue!15]},level distance=1cm]
\tikzstyle{level 2}=[sibling distance=10mm,font=\small,set style={{every node}+=[fill=yellow]}, level distance=0.9cm]
\node{Total}[edge from parent fork down]
 child {node {X}
   child {node {AX}}
   child {node {BX}}
 }
 child {node {Y}
   child {node {AY}}
   child {node {BY}}
 };
\end{tikzpicture}
\end{block}
\end{minipage}

\pause\alert{Examples}

 * Tourism by state and purpose of travel
 * Retail sales by product groups/sub groups, and by countries/regions

## Creating aggregates
\fontsize{8}{8}\sf

```{r tourism_aggregate}
tourism %>%
  aggregate_key(Purpose * (State / Region), Trips = sum(Trips)) %>%
  filter(Quarter == yearquarter("1998 Q1")) %>%
  print(n = 15)
```

## Creating aggregates
\fontsize{13}{15}\sf

 * A grouped structure is specified using `grp1 * grp2`
 * A nested structure is specified via `parent / child`.
 * Groups and nesting can be mixed:

    ```r
    (country/region/city) * (brand/product)
    ```

 * All possible aggregates are produced.
 * These are useful when forecasting at different levels of aggregation.

## The problem
\fontsize{13}{14}\sf

\begin{alertblock}{}
\begin{enumerate}\tightlist
 \item How to forecast time series at all nodes such that the forecasts add up in the same way as the original data?
 \item Can we exploit relationships between the series to improve the forecasts?
\end{enumerate}
\end{alertblock}\pause

### The solution

1. Forecast all series at all levels of aggregation using an automatic forecasting algorithm.\newline (e.g., `ETS`, `ARIMA`, ...)
2. Reconcile the resulting forecasts so they add up correctly using least squares optimization (i.e., find closest reconciled forecasts to the original forecasts).
3. This is available using `reconcile()`.

## Forecast reconciliation
\fontsize{9}{10}\sf

```{r tourismets_reconciled, message=FALSE}
tourism %>%
  aggregate_key(Purpose * (State / Region), Trips = sum(Trips)) %>%
  model(ets = ETS(Trips)) %>%
  reconcile(ets_adjusted = min_trace(ets)) %>%
  forecast(h = 2)
```

## Hierarchical and grouped time series

Every collection of time series with aggregation constraints can be written as
\begin{block}{}
\centerline{$\by_{t}=\bS\bm{b}_{t}$}
\end{block}
where

 * $\by_t$ is a vector of all series at time $t$
 * $\bm{b}_t$ is a vector of the most disaggregated series at time $t$
 * $\bS$ is a ``summing matrix'' containing the aggregation constraints.

## Hierarchical time series

\begin{minipage}{4cm}\vspace*{0.2cm}
\begin{block}{}\centering
\begin{tikzpicture}
\tikzstyle{every node}=[ellipse,draw,fill=red!15,inner sep=2pt]
\tikzstyle[level distance=.3cm]
\tikzstyle[sibling distance=12cm]
\tikzstyle{level 1}=[sibling distance=10mm,font=\small,set style={{every node}+=[fill=blue!15]}]
\node{Total}[edge from parent fork down]
 child {node {A}
 }
 child {node {B}
 }
 child {node {C}
 };
\end{tikzpicture}
\end{block}
\end{minipage}

\only<2->{\begin{textblock}{6.3}(6,1)\small
\begin{itemize}\itemsep=0cm\parskip=0cm
\item[$ y_{t}: $] observed aggregate of all series at time
$t$.
\item[$ y_{X,t}: $] observation on series $X$ at time $t$.
\item[$ \bm{b}_{t}: $] vector of all series at bottom level
in time $t$.
\end{itemize}
\end{textblock}}\vspace*{0.6cm}
\only<3->{
$\bY_{t}= \begin{pmatrix}
  y_{t}\\
  y_{A,t}\\
  y_{B,t}\\
  y_{C,t}
  \end{pmatrix} = \only<3>{\hspace*{0.01cm}\begin{pmatrix}
                1 & 1 & 1 \\
                1 & 0 & 0 \\
                0 & 1 & 0\\
                0 & 0 & 1
                \end{pmatrix}}\only<4->{{\color{blue}\underbrace{\begin{pmatrix}
                1 & 1 & 1 \\
                1 & 0 & 0 \\
                0 & 1 & 0\\
                0 & 0 & 1
                \end{pmatrix}}_{\bS}}}\only<3>{\hspace*{0.08cm}}\only<3>{\hspace*{-0.1cm}\begin{pmatrix}y_{A,t}\\y_{B,t}\\y_{C,t}\end{pmatrix}}\rule{0cm}{1.6cm}
                \only<4->{\hspace*{0.08cm}{\color{red}\underbrace{\begin{pmatrix}y_{A,t}\\y_{B,t}\\y_{C,t}\end{pmatrix}}_{\bm{b}_{t}}}}$}

\vspace*{-0.6cm}

\only<4>{\hspace*{8cm}\colorbox[RGB]{210,210,210}{$\bY_{t}=\color{blue}\bS\color{red}\bm{b}_{t}$}}

\vspace*{10cm}

## Forecasting notation

Let $\hat{\by}_n(h)$ be vector of initial $h$-step forecasts, made at time $n$, stacked in same order as $\by_t$. \pause\newline  (In general, they will not ``add up''.)\pause

\begin{block}{}
Reconciled forecasts must be of the form:
$$\tilde{\by}_{n}(h)=\bS\bm{G}\hat{\by}_{n}(h)$$
for some matrix $\bm{G}$.
\end{block}\pause

 * $\bm{G}$ extracts and combines base forecasts $\hat{\by}_{n}(h)$ to get bottom-level forecasts.
 * $\bS$ adds them up

## Optimal combination forecasts
\fontsize{13}{14}\sf

\begin{alertblock}{Main result}
The best (minimum sum of variances) unbiased forecasts are obtained when
$\bm{G} = (\bS'\bW^{-1}_{h}\bS)^{-1}\bS'\bW^{-1}_{h}$,
where $\bW_h$ is the $h$-step base forecast error covariance matrix.
\end{alertblock}

\pause

\begin{block}{}
\centerline{$\displaystyle\textcolor{red}{\tilde{\by}_{n}(h)}
=\bS(\bS'\bW^{-1}_{h}\bS)^{-1}\bS'\bW^{-1}_{h}\textcolor{blue}{\hat{\by}_{n}(h)}$}
\end{block}\fontsize{14}{15}\sf

\alert{\textbf{Problem:}} $\bW_h$ hard to estimate, especially for $h>1$.

\alert{Solutions:}\vspace*{-0.2cm}

 * Ignore $\bW_h$ (OLS) 
 * Assume $\bW_h = k_h\bW_1$ is diagonal (WLS)  
 * Assume $\bW_h = k_h\bW_1$ and estimate it (GLS) --- the default uses a shrinkage covariance estimator

## Features
\fontsize{15}{17}\sf

 * Covariates can be included in initial forecasts.
 * Adjustments can be made to initial forecasts at any level.
 * Very simple and flexible method. Can work with *any* hierarchical or grouped time series.
 * Conceptually easy to implement: regression of base forecasts on structure matrix.

## Example: Australian tourism
\fontsize{12}{13}\sf

```{r fctourism}
tourism_agg <- tourism %>%
  aggregate_key(Purpose * (State / Region),
    Trips = sum(Trips)
  )
fc <- tourism_agg %>%
  filter(year(Quarter) < 2015) %>%
  model(ets = ETS(Trips)) %>%
  reconcile(ets_adjusted = min_trace(ets)) %>%
  forecast(h = "3 years")
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism2, dependson='fctourism'}
fc %>%
  filter(is_aggregated(Purpose) & is_aggregated(State)) %>%
  autoplot(tourism_agg, level = 95)
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism3, dependson='fctourism'}
fc %>%
  filter(is_aggregated(Purpose) & State == "VIC" &
    is_aggregated(Region)) %>%
  autoplot(tourism_agg, level = 95)
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism4, dependson='fctourism'}
fc %>%
  filter(is_aggregated(Purpose) & Region == "Melbourne") %>%
  autoplot(tourism_agg, level = 95)
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism5, dependson='fctourism'}
fc %>%
  filter(is_aggregated(Purpose) & Region == "Snowy Mountains") %>%
  autoplot(tourism_agg, level = 95)
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism6, dependson='fctourism'}
fc %>%
  filter(Purpose == "Holiday" & Region == "Barossa") %>%
  autoplot(tourism_agg, level = 95)
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism7, dependson='fctourism'}
fc %>%
  filter(is_aggregated(Purpose) & Region == "MacDonnell") %>%
  autoplot(tourism_agg, level = 95)
```

## Forecast evaluation
\fontsize{10}{11}\sf

```{r fcaccuracy, dependson='fctourism'}
fc %>% 
  accuracy(tourism, measures = list(MSE=MSE, CRPS=CRPS))
```

\vspace*{10cm}

## Forecast evaluation
\fontsize{11}{11}\sf

```{r fcaccuracy2, dependson='fctourism'}
fc %>%
  accuracy(tourism, measures = list(MSE=MSE, CRPS=CRPS)) %>%
  group_by(.model) %>%
  summarise(MSE = mean(MSE), CRPS=mean(CRPS))
```

\vspace*{10cm}

## More information
\fontsize{18}{20}\sf

 * Slides and papers: **robjhyndman.com**
 * Packages: **tidyverts.org**
 * Forecasting textbook using tidyverts package: **OTexts.com/fpp3**

\begin{textblock}{8}(7.6,4.8)
\begin{alertblock}{Find me at \dots}
\href{https://twitter.com/robjhyndman}{\faicon{twitter} @robjhyndman}

\href{https://github.com/robjhyndman}{\faicon{github}  @robjhyndman}

\href{https://robjhyndman.com}{\faicon{home} robjhyndman.com}

\href{mailto:rob.hyndman@monash.edu}{\faicon{envelope} rob.hyndman@monash.edu}
\end{alertblock}
\end{textblock}
\vspace*{10cm}

 * ensemble and hybrid forecasts
